{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all relevant packages and code\n",
    "\n",
    "load('Falcon_stuff.sage')\n",
    "load('CBD_stuff.sage')\n",
    "\n",
    "falcon512=distribution(falcon512dist)\n",
    "falcon1024=distribution(falcon1024dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability distributions are handled using dictionaries p, where the probability of sampling i is defined via\n",
    "# p[i] (if i can be sampled)\n",
    "\n",
    "B1_pdist={\n",
    "    -1:1/4,\n",
    "     0:2/4,\n",
    "     1:1/4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution with sampling probabilities:\n",
      "         0 : 1/2\n",
      "     -1, 1 : 1/4\n",
      "\n",
      "Entropy of distribution is 1.0397207708399179\n",
      "\n",
      "Distribution with sampling probabilities:\n",
      "         0 : 1/2\n",
      "     -1, 1 : 1/4\n",
      "\n",
      "Entropy of distribution is 1.5\n"
     ]
    }
   ],
   "source": [
    "# The distribution class takes as input a probability distribution and optional value base, which denotes the\n",
    "# entropy base. If unchanged, the latter is set to 2.\n",
    "\n",
    "B1e=distribution(B1_pdist, base=e)\n",
    "print(B1e)\n",
    "print()\n",
    "\n",
    "B1=distribution(B1_pdist)\n",
    "print(B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distribution with sampling probabilities:\n",
       "         0 : 3/8\n",
       "     -1, 1 : 1/4\n",
       "     -2, 2 : 1/16\n",
       "\n",
       "Entropy of distribution is 2.0306390622295667"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the input probability distribution is not normalized, distribution class automatically normalizes it\n",
    "\n",
    "B2_pdist={\n",
    "    -2:1,\n",
    "    -1:4,\n",
    "     0:6,\n",
    "     1:4,\n",
    "     2:1,\n",
    "}\n",
    "\n",
    "B2=distribution(B2_pdist)\n",
    "B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distribution with sampling probabilities:\n",
       "         0 : 46189/262144\n",
       "     -1, 1 : 20995/131072\n",
       "     -2, 2 : 62985/524288\n",
       "     -3, 3 : 4845/65536\n",
       "     -4, 4 : 4845/131072\n",
       "     -5, 5 : 969/65536\n",
       "     -6, 6 : 4845/1048576\n",
       "     -7, 7 : 285/262144\n",
       "     -8, 8 : 95/524288\n",
       "     -9, 9 : 5/262144\n",
       "   -10, 10 : 1/1048576\n",
       "\n",
       "Entropy of distribution is 3.2077226571333863"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This program comes with 5 predefined distributions: B1, B2, B3, Falcon512 (~D(4.06)) and Falcon1024 (~D(2.87)).\n",
    "# Additionally, other centered binomial distributions with parameter eta can be created via CBD(eta)\n",
    "\n",
    "B10=CBD(10)\n",
    "B10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-2: 1/16, -1: 1/4, 0: 3/8, 1: 1/4, 2: 1/16}\n",
      "2.0306390622295667\n"
     ]
    }
   ],
   "source": [
    "# The normalized probability distribution of a distribution class object can be called with self.dist or self.d .\n",
    "# The entropy is returned with self.entropy .\n",
    "\n",
    "print(B2.dist)\n",
    "print(B2.entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/8, 1/4, 1/16]\n",
      "[1.4150374992788437, 2.0, 4.0]\n",
      "[1, 2, 2]\n",
      "{3/8: [0], 1/4: [-1, 1], 1/16: [-2, 2]}\n"
     ]
    }
   ],
   "source": [
    "# To see every unique probability value that exists in the distribution, call self.p (or self.log_p for\n",
    "# their absolute log-values).\n",
    "\n",
    "print(B2.p)\n",
    "print(B2.log_p)\n",
    "\n",
    "# To see how often these occur, call self.m; the latter is ordered such that self.p[i] appears self.m[i] many times:\n",
    "\n",
    "print(B2.m)\n",
    "\n",
    "# To see all possible sampling values, sorted by their probability of sampling, call self.label\n",
    "\n",
    "print(B2.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[-2, -1, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# The size of range of possible probabilities is denoted with eta. Since we generally deal\n",
    "# with distributions that are centered around 0, this usually coincides with the sampling range [-eta , ... , eta].\n",
    "# The range can be called with self.range\n",
    "\n",
    "print(B2.eta)\n",
    "print(B2.range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/16\n",
      "0\n",
      "3/2048\n",
      "3/2048\n",
      "0.00146484375\n"
     ]
    }
   ],
   "source": [
    "# To find the probability of sampling a certain i, call self.prob(i). Can also be called for elements not in\n",
    "# the sampling range\n",
    "\n",
    "print(B2.prob(2))\n",
    "print(B2.prob('Hello World'))\n",
    "\n",
    "# To find the probability of sampling a certain vector v, call self.vec_prob(v)\n",
    "\n",
    "print(B2.vec_prob([-2, 1, 0, -1]))\n",
    "\n",
    "# A more compact way of representing a vector (and its unsigned permutations) is by counting\n",
    "# how often a certain position/ probability occurs. For example, [-2, 1, 0, -1] can be represented\n",
    "# by counting every 0, every +1, -1 and every +2, -2 and putting these weights in the list l = [1, 2, 1]\n",
    "# to find the probability of a vector with only stating its weights can be done with self.compact_vec_prob(l)\n",
    "\n",
    "print(B2.compact_vec_prob([1, 2, 1]))\n",
    "\n",
    "# each probability function has optional input f, which, if set to true, converts the output to float:\n",
    "\n",
    "print(B2.compact_vec_prob([1, 2, 1], f = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List with all 15 different weight distributions\n",
      "List with 11 different weight distributions, each having probability at least 2^(-H(.)n-2), total probability is 0.879\n",
      "List with 7 different weight distributions, each having probability at least 2^(-H(.)n), total probability is 0.525\n",
      "List with 2 different weight distributions, each having probability at least 2^(-H(.)n+2), total probability is 0.057\n"
     ]
    }
   ],
   "source": [
    "# The calculation of (expected) runtimes requires the ability to build compact dictionaries.\n",
    "# To create a compact dictionary for dimension n, call self.comp_dic(n):\n",
    "\n",
    "print(B2.comp_dic(4))\n",
    "\n",
    "# Note that these dictionaries are of size O(n^eta), which can be very large for wide distributions\n",
    "# (like D(4.06) or D(2.87)). To combat this, we can create partial compact dictionaries that only contain\n",
    "# vectors above a certain probability threshold, say 2^(-H(.)n-c) for entropy H(.) and some constant c.\n",
    "# To create such an partial compact dictionary, call self.par_comp_dic(n, c):\n",
    "\n",
    "print(B2.par_comp_dic(5,2))\n",
    "print(B2.par_comp_dic(5,0))\n",
    "print(B2.par_comp_dic(5,-2))\n",
    "\n",
    "# If a partial compact dictionary has been calculated previously vor parameters (n, c) and the function is\n",
    "# called again for (n, c') where c' < c, the former list can be reused to calculate the compact dictionary faster. \n",
    "# If c' > c, we have to restart the whole computation process. We can not use the previous partial compact dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: List with all 15 different weight distributions, 5: List with 11 different weight distributions, each having probability at least 2^(-H(.)n-2), total probability is 0.879}\n",
      "List with 11 different weight distributions, each having probability at least 2^(-H(.)n-2), total probability is 0.879\n",
      "List with 0 different weight distributions, each having probability at least 2^(-H(.)n+inf), total probability is 0.000\n"
     ]
    }
   ],
   "source": [
    "# distribution class objects contain a pointer to all their peviously created compact dictionaries. These\n",
    "# pointers can be found in the dictionary self.comp_dics:\n",
    "\n",
    "print(B2.comp_dics)\n",
    "\n",
    "# To call a specific (partial) compact dictionary for dimension n, call self.comp_dic_list(n):\n",
    "\n",
    "print(B2.comp_dic_list(5))\n",
    "\n",
    "# If said compact dictionary has not yet been computed, this returns an empty compact dictionary instead:\n",
    "\n",
    "print(B2.comp_dic_list(2**16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[5, 0, 0], 243/32768, 1],\n",
       " [[4, 1, 0], 81/16384, 10],\n",
       " [[3, 2, 0], 27/8192, 40],\n",
       " [[2, 3, 0], 9/4096, 80],\n",
       " [[1, 4, 0], 3/2048, 80],\n",
       " [[4, 0, 1], 81/65536, 10],\n",
       " [[0, 5, 0], 1/1024, 32],\n",
       " [[3, 1, 1], 27/32768, 80],\n",
       " [[2, 2, 1], 9/16384, 240],\n",
       " [[1, 3, 1], 3/8192, 320],\n",
       " [[0, 4, 1], 1/4096, 160]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compact dictionaries are their own class. To access the actual dictionary, call self_cd.dic\n",
    "\n",
    "ex_cd=B2.comp_dic_list(5)\n",
    "ex_cd.dic\n",
    "\n",
    "# every item in self_cd.dic is a list that contains 3 items: the actual weight distribution, the sampling distribution\n",
    "# for a vector with said distribution and the amount of vectors that have this unsigned weight distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053\n",
      "7203/8192\n"
     ]
    }
   ],
   "source": [
    "# To retreive the amount of vectors that are represented with the stored partial dictionary, call self_cd.count\n",
    "\n",
    "print(ex_cd.count)\n",
    "\n",
    "# The cumulative sampling probability of all these vectors can be returned with self_cd.p\n",
    "\n",
    "print(ex_cd.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-inf\n",
      "8.877443751081733\n"
     ]
    }
   ],
   "source": [
    "# The value for c from function call self.par_comp_dic(n, c) is stored in self_cd.c\n",
    "\n",
    "print(ex_cd.c)\n",
    "\n",
    "# The empty compact dictionary has value c set to -inf. Compact dictionaries created with calling self.comp_dic(n)\n",
    "# have their value of c set to -(H(.)-max(self.log_p))n+1\n",
    "\n",
    "print(empty_comp_dic.c)\n",
    "print(B2.comp_dic_list(4).c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epsilon coresize Eclassic Equantum\n",
      "1 0.875000 1.5849625007211563 1.0 0.21607124505355713\n",
      "2 0.765625 3.1699250014423126 2.4429434958487284 0.599744272000731\n",
      "3 0.669922 4.754887502163469 4.057314877782703 1.0849045981735483\n",
      "\n",
      "n epsilon coresize Eclassic Equantum\n",
      "1 1.000000 2.321928094887362 1.1292830169449666 0.5122980368899775\n",
      "2 0.984375 4.392317422778761 2.7911628885550184 1.2355882344416627\n",
      "3 0.957031 6.339850002884625 4.685898549158372 2.0491882466180544\n",
      "\n",
      "n epsilon coresize Eclassic Equantum\n",
      "1 0.875000 1.5849625007211563 1.0 0.21607124505355713\n",
      "3 0.669922 4.754887502163469 4.057314877782703 1.0849045981735483\n",
      "5 0.525269 7.98299357469431 7.416738651220243 2.2382946423532286\n",
      "\n",
      "n epsilon coresize Eclassic Enoabort Equantum\n",
      "1 0.875000 1.5849625007211563 1.0 1.1292830169449666 0.21607124505355713\n",
      "2 0.765625 3.1699250014423126 2.4429434958487284 2.799281621521922 0.599744272000731\n",
      "3 0.669922 4.754887502163469 4.057314877782703 4.728292564047243 1.0849045981735483\n",
      "\n",
      "[4, 5, 1, 2, 3]\n",
      "n epsilon coresize Eclassic Equantum\n",
      "1 0.875000 1.5849625007211563 1.0 0.21607124505355713\n",
      "2 0.765625 3.1699250014423126 2.4429434958487284 0.599744272000731\n",
      "3 0.669922 4.754887502163469 4.057314877782703 1.0849045981735483\n",
      "[4, 5]\n"
     ]
    }
   ],
   "source": [
    "# To create csv-style tables containing raw data for n in range [low_n, high_n], call self.raw_data():\n",
    "\n",
    "B2.raw_data(1,3)\n",
    "print()\n",
    "\n",
    "# the column heads of the csv table are\n",
    "# n: vector dimension n\n",
    "# p: probability that a randomly sampled vector has sampling probability 2^(-H(.)n-c)\n",
    "# coresize: amount of vectors that satisfy the above condition (i.e. size of core set)\n",
    "# Eclassic: expected runtime of running AbortedKeyGuess on that set of vectors\n",
    "# Equantum: expected runtime of running Montanaro's algorithm on the very set of vectors\n",
    "\n",
    "# By default, we set c to 0. If another calue for c is required, c can optionally be altered:\n",
    "\n",
    "B2.raw_data(1,3, c=3)\n",
    "print()\n",
    "\n",
    "# If not every element from that range is required, the step size can be increased with the optional step command:\n",
    "\n",
    "B2.raw_data(1,5, step=2)\n",
    "print()\n",
    "\n",
    "# Since we do not need the complete compact dictionary except when we compare the expected runtimes of KeyGuess\n",
    "# and AbortedKeyGuess, we omit the expected runtime of KeyGuess unless specifically asked for. This can be done\n",
    "# with the optional command aborts = False:\n",
    "\n",
    "B2.raw_data(1,3, aborts = False)\n",
    "print()\n",
    "\n",
    "# The last function call has an additional column that contains the expected runtime of KeyGuess with column head\n",
    "# Enoabort: Expected runtime of KeyGuess\n",
    "\n",
    "# If the compact dictionaries are no longer required after the csv table is computed, the optional command\n",
    "# delete_after can be set to true to immediately delete the compact dictionaries:\n",
    "\n",
    "print(list(B2.comp_dics))\n",
    "B2.raw_data(1,3, delete_after = True)\n",
    "print(list(B2.comp_dics))\n",
    "\n",
    "# Note how the last call of B2.comp_dics does not contain the keys n = 1, 2, 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.3",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
