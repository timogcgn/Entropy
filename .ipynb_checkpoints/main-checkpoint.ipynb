{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all relevant packages and code\n",
    "\n",
    "load('Falcon_stuff.sage')\n",
    "load('New_Falcon_stuff.sage')\n",
    "load('CBD_stuff.sage')\n",
    "\n",
    "import gc\n",
    "\n",
    "from Entropy_stuff import *\n",
    "from Multinomial import *\n",
    "from Largelog import *\n",
    "from Root_sum import approx_sum_of_roots\n",
    "from Compact_Dictionary import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1024=func_distribution('Falcon1024', distribution_falcon, [falcon1024_sigma], ['sigma'])\n",
    "f512=func_distribution('Falcon512', distribution_falcon, [falcon512_sigma], ['sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f512_old=distribution(falcon512dist)\n",
    "f1024_old=distribution(falcon1024dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5661440663728756"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1024.entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8660196105754623 1.0\n",
      "4.053163803303075 1.0\n"
     ]
    }
   ],
   "source": [
    "for key in falcon_denominator:\n",
    "    print(key, 1-exp(-falcon_denominator[key][2]^2/(2*key^2))/falcon_denominator[key][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2.8660196105754623: (1/1024, 7.184045791515382, 58),\n",
       " 4.053163803303075: (1/1024, 10.159774991070414, 115)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epsilon coresize Eclassic Equantum\n",
      "35 0.531842 121.41824142138923 120.57814161579697 58.093743261443684\n"
     ]
    }
   ],
   "source": [
    "fon.make_raw_data(35,35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List with 3068512 different weight distributions, each having probability at least 2^(-H(.)n), total probability is 0.532"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fon.comp_dics[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=0\n",
    "d=[]\n",
    "for item in fon.comp_dics[35].dic:\n",
    "    if len(item[0])>l:\n",
    "        l=len(item[0])\n",
    "        d=item\n",
    "l-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 0\n",
      "[[35, 0], 1.0643434307797327e-30, 1]\n",
      "2 1.0643434307797327e-30\n"
     ]
    }
   ],
   "source": [
    "for l2 in range(3):\n",
    "    s=0\n",
    "    for item in fon.comp_dics[35].dic:\n",
    "        if len(item[0])==l2:\n",
    "            s+=item[1]*item[2]\n",
    "            print(item)\n",
    "    print(l2, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0643434307797327e-30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_falcon(0, [falcon1024_sigma])^35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0033840167589857e-175"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fon.compact_vec_prob(10*[0]+[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List with 3068512 different weight distributions, each having probability at least 2^(-H(.)n), total probability is 0.532"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fon.comp_dics[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epsilon coresize Eclassic Equantum\n",
      "1 0.619382 2.321928094887362 1.8793961403083732 0.019355426840186447\n",
      "2 0.612300 5.614709844115208 4.998576129835446 1.396200489884324\n",
      "9 0.558748 29.626615833872236 28.892539656641677 12.860683301670868\n",
      "8 0.564781 26.160108715845645 25.429941138995858 11.18093095332935\n",
      "7 0.571430 22.700856014841396 21.976033594107232 9.509728871337007\n",
      "6 0.578380 19.247883485213144 18.531296999703176 7.846926456213738\n",
      "5 0.585404 15.802844488420687 15.098744525253863 6.1938176558252795\n",
      "4 0.580875 12.3063465536885 11.642630122949562 4.5024515556021845\n",
      "3 0.592002 8.92184093707449 8.27797214160556 2.9060026393004987\n",
      "10 0.563695 33.18486105778719 32.42576993457002 14.607639267005238\n"
     ]
    }
   ],
   "source": [
    "print(\"n epsilon coresize Eclassic Equantum\")\n",
    "for _,data in fon.single_raw_data(list(range(1,11))):\n",
    "    print(data[0], data[1], data[2], data[3], data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_falcon(50,[falcon1024_sigma])>2**(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2.8660196105754623: (1/1024, 7.184045791515382),\n",
       " 4.053163803303075: (1/1024, 10.159774991070414)}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1024=create_falcon_dist(falcon1024_sigma,denominator_goodness_ratio=2**(-10))\n",
    "f512=create_falcon_dist(falcon512_sigma,denominator_goodness_ratio=2**(-10))\n",
    "b1024=create_falcon_dist(falcon1024_sigma,denominator_goodness_ratio=2**(-10), give_b=True)\n",
    "b512=create_falcon_dist(falcon512_sigma,denominator_goodness_ratio=2**(-10), give_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epsilon coresize Eclassic Equantum\n",
      "1 0.619382 2.321928094887362 1.8793961403041906 0.019355426851838498\n",
      "2 0.612300 5.614709844115208 4.9985761298230305 1.396200489907629\n",
      "9 0.558748 29.626615833872236 28.892539656572115 12.860683301775289\n",
      "8 0.564781 26.160108715845645 25.42994113893444 11.180930953473572\n",
      "7 0.571430 22.700856014841396 21.976033594053998 9.509728872319922\n",
      "6 0.578380 19.247883485213144 18.5312969996582 7.846926519284773\n",
      "5 0.585404 15.802844488420687 15.098744525217212 6.19381807952662\n",
      "4 0.580875 12.3063465536885 11.642630122922336 4.502451555648793\n",
      "3 0.592002 8.92184093707449 8.277972141585897 2.906002639335455\n",
      "10 0.563695 33.18486105778719 32.42576993448934 14.607639267121645\n"
     ]
    }
   ],
   "source": [
    "print(\"n epsilon coresize Eclassic Equantum\")\n",
    "for _,data in f1024.single_raw_data(list(range(1,11))):\n",
    "    print(data[0], data[1], data[2], data[3], data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epsilon coresize Eclassic Equantum\n",
      "1 0.734323 3.1699250014423126 2.5241578288943023 0.586728930497192\n",
      "2 0.624528 6.6582114827517955 6.016977726573837 1.929670071881489\n",
      "9 0.560391 34.13961272031239 33.40201475397928 15.11973518791987\n",
      "8 0.566575 30.17371523703035 29.43969224230189 13.190447822112723\n",
      "7 0.567300 26.17275056379007 25.456013974805327 11.238193060563955\n",
      "6 0.575557 22.23049927049313 21.519144185800304 9.332775933392126\n",
      "5 0.587408 18.315481285939416 17.60718505858842 7.453056003142082\n",
      "4 0.588176 14.348244039977779 13.670030612361858 5.534772658934438\n",
      "3 0.601874 10.470658874060552 9.807839848373183 3.695159084089695\n",
      "10 0.560539 38.159161884818175 37.40671342747216 17.08947092456333\n"
     ]
    }
   ],
   "source": [
    "print(\"n epsilon coresize Eclassic Equantum\")\n",
    "for _,data in f512.single_raw_data(list(range(1,11))):\n",
    "    print(data[0], data[1], data[2], data[3], data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distribution with sampling probabilities:\n",
       "         0 : 72973/524288\n",
       "     -1, 1 : 2151/16384\n",
       "     -2, 2 : 113981/1048576\n",
       "     -3, 3 : 84393/1048576\n",
       "     -4, 4 : 55367/1048576\n",
       "     -5, 5 : 3983/131072\n",
       "     -6, 6 : 8099/524288\n",
       "     -7, 7 : 3711/524288\n",
       "     -8, 8 : 1465/524288\n",
       "     -9, 9 : 1055/1048576\n",
       "   -10, 10 : 307/1048576\n",
       "   -11, 11 : 109/1048576\n",
       "   -12, 12 : 11/524288\n",
       "   -13, 13 : 3/1048576\n",
       "\n",
       "Entropy of distribution is 3.565524024663833"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution(falcon1024dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 0.32650268007320027, 0: 0.34699463985359946, 1: 0.32650268007320027}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounded_gaussian(1,falcon1024_sigma).dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_A=distribution(falcon512dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epsilon coresize Eclassic Equantum\n",
      "1 0.875000 1.5849625007211563 1.0 0.21607124505355713\n",
      "2 0.765625 3.1699250014423126 2.4429434958487284 0.599744272000731\n",
      "3 0.669922 4.754887502163469 4.057314877782703 1.0849045981735483\n"
     ]
    }
   ],
   "source": [
    "B2.raw_data(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2930696285017828"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(PDF_gaussian(-1,200,4)+PDF_gaussian(0,200,4)+PDF_gaussian(1,200,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds={}\n",
    "ds.get(1,1)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability distributions are handled using dictionaries p, where the probability of sampling i is defined via\n",
    "# p[i] (if i can be sampled)\n",
    "\n",
    "B1_pdist={\n",
    "    -1:1/4,\n",
    "     0:2/4,\n",
    "     1:1/4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution class takes as input a probability distribution and optional value base, which denotes the\n",
    "# entropy base. If unchanged, the latter is set to 2.\n",
    "\n",
    "B1e=distribution(B1_pdist, base=e)\n",
    "print(B1e)\n",
    "print()\n",
    "\n",
    "B1=distribution(B1_pdist)\n",
    "print(B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the input probability distribution is not normalized, distribution class automatically normalizes it\n",
    "\n",
    "B2_pdist={\n",
    "    -2:1,\n",
    "    -1:4,\n",
    "     0:6,\n",
    "     1:4,\n",
    "     2:1,\n",
    "}\n",
    "\n",
    "B2=distribution(B2_pdist)\n",
    "B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program comes with 5 predefined distributions: B1, B2, B3, Falcon512 (~D(4.06)) and Falcon1024 (~D(2.87)).\n",
    "# Additionally, other centered binomial distributions with parameter eta can be created via CBD(eta)\n",
    "\n",
    "B10=CBD(10)\n",
    "B10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The normalized probability distribution of a distribution class object can be called with self.dist or self.d .\n",
    "# The entropy is returned with self.entropy .\n",
    "\n",
    "print(B2.dist)\n",
    "print(B2.entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see every unique probability value that exists in the distribution, call self.p (or self.log_p for\n",
    "# their absolute log-values).\n",
    "\n",
    "print(B2.p)\n",
    "print(B2.log_p)\n",
    "\n",
    "# To see how often these occur, call self.m; the latter is ordered such that self.p[i] appears self.m[i] many times:\n",
    "\n",
    "print(B2.m)\n",
    "\n",
    "# To see all possible sampling values, sorted by their probability of sampling, call self.label\n",
    "\n",
    "print(B2.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of range of possible probabilities is denoted with eta. Since we generally deal\n",
    "# with distributions that are centered around 0, this usually coincides with the sampling range [-eta , ... , eta].\n",
    "# The range can be called with self.range\n",
    "\n",
    "print(B2.eta)\n",
    "print(B2.range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the probability of sampling a certain i, call self.prob(i). Can also be called for elements not in\n",
    "# the sampling range\n",
    "\n",
    "print(B2.prob(2))\n",
    "print(B2.prob('Hello World'))\n",
    "\n",
    "# To find the probability of sampling a certain vector v, call self.vec_prob(v)\n",
    "\n",
    "print(B2.vec_prob([-2, 1, 0, -1]))\n",
    "\n",
    "# A more compact way of representing a vector (and its unsigned permutations) is by counting\n",
    "# how often a certain position/ probability occurs. For example, [-2, 1, 0, -1] can be represented\n",
    "# by counting every 0, every +1, -1 and every +2, -2 and putting these weights in the list l = [1, 2, 1]\n",
    "# to find the probability of a vector with only stating its weights can be done with self.compact_vec_prob(l)\n",
    "\n",
    "print(B2.compact_vec_prob([1, 2, 1]))\n",
    "\n",
    "# each probability function has optional input f, which, if set to true, converts the output to float:\n",
    "\n",
    "print(B2.compact_vec_prob([1, 2, 1], f = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The calculation of (expected) runtimes requires the ability to build compact dictionaries.\n",
    "# To create a compact dictionary for dimension n, call self.comp_dic(n):\n",
    "\n",
    "print(B2.comp_dic(4))\n",
    "\n",
    "# Note that these dictionaries are of size O(n^eta), which can be very large for wide distributions\n",
    "# (like D(4.06) or D(2.87)). To combat this, we can create partial compact dictionaries that only contain\n",
    "# vectors above a certain probability threshold, say 2^(-H(.)n-c) for entropy H(.) and some constant c.\n",
    "# To create such an partial compact dictionary, call self.par_comp_dic(n, c):\n",
    "\n",
    "print(B2.par_comp_dic(5,2))\n",
    "print(B2.par_comp_dic(5,0))\n",
    "print(B2.par_comp_dic(5,-2))\n",
    "\n",
    "# If a partial compact dictionary has been calculated previously for parameters (n, c) and the function is\n",
    "# called again for (n, c') where c' < c, the former list can be reused to calculate the compact dictionary faster. \n",
    "# If c' > c, we have to restart the whole computation process. We can not use the previous partial compact dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution class objects contain a pointer to all their peviously created compact dictionaries. These\n",
    "# pointers can be found in the dictionary self.comp_dics:\n",
    "\n",
    "print(B2.comp_dics)\n",
    "\n",
    "# To call a specific (partial) compact dictionary for dimension n, call self.comp_dic_list(n):\n",
    "\n",
    "print(B2.comp_dic_list(5))\n",
    "\n",
    "# If said compact dictionary has not yet been computed, this returns an empty compact dictionary instead:\n",
    "\n",
    "print(B2.comp_dic_list(2**16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compact dictionaries are their own class. To access the actual dictionary, call self_cd.dic\n",
    "\n",
    "ex_cd=B2.comp_dic_list(5)\n",
    "ex_cd.dic\n",
    "\n",
    "# every item in self_cd.dic is a list that contains 3 items: the actual weight distribution, the sampling distribution\n",
    "# for a vector with said distribution and the amount of vectors that have this unsigned weight distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retreive the amount of vectors that are represented with the stored partial dictionary, call self_cd.count\n",
    "\n",
    "print(ex_cd.count)\n",
    "\n",
    "# The cumulative sampling probability of all these vectors can be returned with self_cd.p\n",
    "\n",
    "print(ex_cd.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value for c from function call self.par_comp_dic(n, c) is stored in self_cd.c\n",
    "\n",
    "print(ex_cd.c)\n",
    "\n",
    "# The empty compact dictionary has value c set to -inf. Compact dictionaries created with calling self.comp_dic(n)\n",
    "# have their value of c set to -(H(.)-max(self.log_p))n+1\n",
    "\n",
    "print(empty_comp_dic.c)\n",
    "print(B2.comp_dic_list(4).c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create csv-style tables containing raw data for n in range [low_n, high_n], call self.raw_data():\n",
    "\n",
    "B2.raw_data(1,3)\n",
    "print()\n",
    "\n",
    "# the column heads of the csv table are\n",
    "# n: vector dimension n\n",
    "# p: probability that a randomly sampled vector has sampling probability 2^(-H(.)n-c)\n",
    "# coresize: amount of vectors that satisfy the above condition (i.e. size of core set)\n",
    "# Eclassic: expected runtime of running AbortedKeyGuess on that set of vectors\n",
    "# Equantum: expected runtime of running Montanaro's algorithm on the very set of vectors\n",
    "\n",
    "# By default, we set c to 0. If another calue for c is required, c can optionally be altered:\n",
    "\n",
    "B2.raw_data(1,3, c=3)\n",
    "print()\n",
    "\n",
    "# If not every element from that range is required, the step size can be increased with the optional step command:\n",
    "\n",
    "B2.raw_data(1,5, step=2)\n",
    "print()\n",
    "\n",
    "# Since we do not need the complete compact dictionary except when we compare the expected runtimes of KeyGuess\n",
    "# and AbortedKeyGuess, we omit the expected runtime of KeyGuess unless specifically asked for. This can be done\n",
    "# with the optional command aborts = False:\n",
    "\n",
    "B2.raw_data(1,3, aborts = False)\n",
    "print()\n",
    "\n",
    "# The last function call has an additional column that contains the expected runtime of KeyGuess with column head\n",
    "# Enoabort: Expected runtime of KeyGuess\n",
    "\n",
    "# If the compact dictionaries are no longer required after the csv table is computed, the optional command\n",
    "# delete_after can be set to true to immediately delete the compact dictionaries:\n",
    "\n",
    "print(list(B2.comp_dics))\n",
    "B2.raw_data(1,3, delete_after = True)\n",
    "print(list(B2.comp_dics))\n",
    "\n",
    "# Note how the last call of B2.comp_dics does not contain the keys n = 1, 2, 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.3",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
